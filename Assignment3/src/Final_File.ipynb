{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Design of a Neural Network from scratch\n",
    "\n",
    "*************<IMP>*************\n",
    "Mention hyperparameters used and describe functionality in detail in this space\n",
    "- carries 1 mark\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class NN: \n",
    "    parameters = list()\n",
    "    \n",
    "    def init_params(self,neuron_count_per_layer):\n",
    "        np.random.seed(10)\n",
    "        num_layers = len(neuron_count_per_layer)\n",
    "        params = [None for i in range(2*(num_layers-1))]\n",
    "        for i in range(1,num_layers):\n",
    "            params[2*i-2]=np.random.randn(neuron_count_per_layer[i], neuron_count_per_layer[i-1]) * 0.01\n",
    "            params[2*i-1]=np.zeros((neuron_count_per_layer[i], 1))\n",
    "        #print(params)\n",
    "        return params\n",
    "    \n",
    "    #Clean the data by replacing the null values with the mean/median/mode of the column\n",
    "    def data_clean(self,df):\n",
    "        df.columns = df.columns.str.strip()\n",
    "        for column in df.columns:\n",
    "            if column in ['Weight','HB','BP']:\n",
    "                df[column].fillna(value=df[column].mean(), inplace=True)\n",
    "            elif column in ['Community','Delivery phase','IFA','Education']:\n",
    "                df[column].fillna(value=df[column].mode()[0], inplace=True)\n",
    "            else:\n",
    "                df[column].fillna(value=df[column].median(), inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def relu(self,Z):\n",
    "        return np.maximum(0,Z),Z\n",
    "    \n",
    "    def sigmoid(self,Z):\n",
    "        return 1/(1+np.exp(-Z)),Z\n",
    "    \n",
    "    def compute_activation(self,A,weight,bias,activation):\n",
    "        Z = weight@A + bias\n",
    "        cache1 = (A,weight,bias)\n",
    "        if activation=='relu':\n",
    "            A1,cache2 = self.relu(Z)\n",
    "        else:\n",
    "            A1,cache2 = self.sigmoid(Z)\n",
    "        return A1,(cache1,cache2)\n",
    "     \n",
    "    def compute_gradients(self,dA,vals,activation):\n",
    "        cache1,cache2 = vals\n",
    "        if activation=='relu':\n",
    "            dZ = np.array(dA,copy=True)\n",
    "            #print(cache2.shape,dA.shape)\n",
    "            dZ[cache2<=0]=0\n",
    "        if activation=='sigmoid':\n",
    "            sig = 1/(1+np.exp(-cache2))\n",
    "            dZ = dA * sig * (1-sig)\n",
    "        A_prev, W, b = cache1\n",
    "        x = A_prev.shape[1]\n",
    "        dW = 1 / x * dZ @ A_prev.T\n",
    "        db = 1 / x * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = W.T @ dZ\n",
    "        return dA_prev,dW,db\n",
    "            \n",
    "    \n",
    "    def forward_propogation(self,X,parameters):\n",
    "        num_layers = len(parameters)//2\n",
    "        back_prop_values = []\n",
    "        A = X\n",
    "        \n",
    "        for i in range(1,num_layers):\n",
    "            prev_act = A\n",
    "            weight = parameters[2*i-2]\n",
    "            bias = parameters[2*i-1]\n",
    "            A,back_prop_value = self.compute_activation(prev_act,weight,bias,activation='relu')\n",
    "            back_prop_values.append(back_prop_value)\n",
    "        \n",
    "    \n",
    "        #For Last layer i.e sigmoid \n",
    "        A,back_prop_value = self.compute_activation(A,parameters[-2],parameters[-1],activation='sigmoid')\n",
    "        back_prop_values.append(back_prop_value) \n",
    "        #print(len(back_prop_values))\n",
    "        return A,back_prop_values\n",
    "    \n",
    "    def back_propogation(self,Y,activations,parameters,back_prop_values,alpha):\n",
    "        #Computing the necessary derivatives\n",
    "        gradients = {}\n",
    "        num_layers = len(parameters)//2\n",
    "        Y.reshape(activations.shape)\n",
    "        dA = - (np.divide(Y, activations) - np.divide(1 - Y, 1 - activations))\n",
    "        #print(dA.shape)\n",
    "        vals = back_prop_values[num_layers-1]\n",
    "        gradients[\"dA\" + str(num_layers-1)], gradients[\"dW\" + str(num_layers)], gradients[\"db\" + str(num_layers)] = self.compute_gradients(dA,vals,'sigmoid')\n",
    "        for layer in reversed(range(num_layers-1)):\n",
    "            vals = back_prop_values[layer]\n",
    "            gradients[\"dA\" + str(layer)], gradients[\"dW\" + str(layer + 1)], gradients[\"db\" + str(layer + 1)] = self.compute_gradients(gradients['dA'+str(layer+1)], vals, 'relu')\n",
    "        \n",
    "        #Updating the parameters\n",
    "        for i in range(1,num_layers+1):\n",
    "            parameters[2*i-2]=parameters[2*i-2] - alpha * gradients['dW'+str(i)]\n",
    "            parameters[2*i-1]=parameters[2*i-1] - alpha * gradients['db'+str(i)]\n",
    "        \n",
    "        return parameters\n",
    "        \n",
    "\n",
    "    def calc_cost(self,A,Y):\n",
    "        return np.squeeze(-1 / len(Y) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A)))\n",
    "\n",
    "    ''' X and Y are dataframes '''\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        '''\n",
    "        Function that trains the neural network by taking x_train and y_train samples as input\n",
    "        '''\n",
    "\n",
    "        #Clean the data\n",
    "        X = self.data_clean(X)\n",
    "        #Set hyperparameters\n",
    "        num_itertations = 20000\n",
    "        alpha = 0.1\n",
    "        \n",
    "    \n",
    "        #Init parameters\n",
    "        neuron_count_per_layer = [9,30,30,25,1]\n",
    "        self.parameters = self.init_params(neuron_count_per_layer)\n",
    "        \n",
    "        #Making necessary changes to dimensions\n",
    "        X = np.transpose(np.array(X))\n",
    "        Y = np.array(Y)\n",
    "        Y = np.reshape(Y,(1,Y.shape[0]))\n",
    "        \n",
    "        for i in range(1,num_itertations+1):\n",
    "            #Fp\n",
    "            activations,back_prop_values = self.forward_propogation(X,self.parameters)\n",
    "            #Bp\n",
    "            self.parameters = self.back_propogation(Y,activations,self.parameters,back_prop_values,alpha)\n",
    "            #Print Cost after every 500 iters\n",
    "            if i%500==0:\n",
    "                print('Cost after iter '+str(i)+ ':' + str(self.calc_cost(activations,Y)/100))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "        \"\"\"\n",
    "        The predict function performs a simple feed forward of weights\n",
    "        and outputs yhat values \n",
    "\n",
    "        yhat is a list of the predicted value for df X\n",
    "        \"\"\"\n",
    "        yhat = []\n",
    "        #X = self.data_clean(X)\n",
    "        X = np.transpose(np.array(X))\n",
    "        yhat = self.forward_propogation(X,self.parameters)[0][0]\n",
    "        return yhat\n",
    "\n",
    "    def CM(self,y_test,y_test_obs):\n",
    "        '''\n",
    "        Prints confusion matrix \n",
    "        y_test is list of y values in the test dataset\n",
    "        y_test_obs is list of y values predicted by the model\n",
    "\n",
    "        '''\n",
    "\n",
    "        for i in range(len(y_test_obs)):\n",
    "            if(y_test_obs[i]>0.6):\n",
    "                y_test_obs[i]=1\n",
    "            else:\n",
    "                y_test_obs[i]=0\n",
    "\n",
    "        cm=[[0,0],[0,0]]\n",
    "        fp=0\n",
    "        fn=0\n",
    "        tp=0\n",
    "        tn=0\n",
    "\n",
    "        for i in range(len(y_test)):\n",
    "            if(y_test[i]==1 and y_test_obs[i]==1):\n",
    "                tp=tp+1\n",
    "            if(y_test[i]==0 and y_test_obs[i]==0):\n",
    "                tn=tn+1\n",
    "            if(y_test[i]==1 and y_test_obs[i]==0):\n",
    "                fp=fp+1\n",
    "            if(y_test[i]==0 and y_test_obs[i]==1):\n",
    "                fn=fn+1\n",
    "        cm[0][0]=tn\n",
    "        cm[0][1]=fp\n",
    "        cm[1][0]=fn\n",
    "        cm[1][1]=tp\n",
    "\n",
    "        p= tp/(tp+fp)\n",
    "        r=tp/(tp+fn)\n",
    "        f1=(2*p*r)/(p+r)\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        print(\"Confusion Matrix : \")\n",
    "        print(cm)\n",
    "        print(\"\\n\")\n",
    "        print(f\"Precision : {p}\")\n",
    "        print(f\"Recall : {r}\")\n",
    "        print(f\"F1 SCORE : {f1}\")\n",
    "        print(f\"Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Community   Age     Weight  Delivery phase        HB  IFA        BP  \\\n",
      "0           1  21.0  42.000000             1.0  9.200000    1  1.375000   \n",
      "1           1  21.0  45.129412             1.0  8.800000    1  1.500000   \n",
      "2           1  21.0  45.129412             1.0  9.200000    1  2.125000   \n",
      "3           1  21.0  45.129412             1.0  8.000000    1  1.375000   \n",
      "4           1  24.0  33.000000             1.0  9.300000    1  1.571000   \n",
      "..        ...   ...        ...             ...       ...  ...       ...   \n",
      "91          3  21.0  55.000000             1.0  9.000000    0  1.375000   \n",
      "92          3  24.0  39.000000             2.0  8.400000    0  1.500000   \n",
      "93          3  24.0  50.000000             1.0  9.076623    0  1.375000   \n",
      "94          1  24.0  38.000000             1.0  9.076623    0  1.725189   \n",
      "95          3  21.0  50.000000             1.0  9.000000    1  1.375000   \n",
      "\n",
      "    Education  Residence  Result  \n",
      "0         5.0        1.0       0  \n",
      "1         5.0        1.0       0  \n",
      "2         5.0        1.0       0  \n",
      "3         5.0        1.0       0  \n",
      "4         5.0        1.0       0  \n",
      "..        ...        ...     ...  \n",
      "91        5.0        1.0       1  \n",
      "92        5.0        1.0       1  \n",
      "93        5.0        1.0       1  \n",
      "94        5.0        1.0       1  \n",
      "95        5.0        1.0       1  \n",
      "\n",
      "[96 rows x 10 columns]     Community   Age  Weight  Delivery phase   HB  IFA     BP  Education  \\\n",
      "0           1  21.0    42.0             1.0  9.2    1  1.375        5.0   \n",
      "1           1  21.0     NaN             1.0  8.8    1  1.500        5.0   \n",
      "2           1  21.0     NaN             1.0  9.2    1  2.125        5.0   \n",
      "3           1  21.0     NaN             1.0  8.0    1  1.375        5.0   \n",
      "4           1  24.0    33.0             1.0  9.3    1  1.571        5.0   \n",
      "..        ...   ...     ...             ...  ...  ...    ...        ...   \n",
      "91          3  21.0    55.0             1.0  9.0    0  1.375        5.0   \n",
      "92          3  24.0    39.0             2.0  8.4    0  1.500        5.0   \n",
      "93          3   NaN    50.0             NaN  NaN    0  1.375        NaN   \n",
      "94          1   NaN    38.0             NaN  NaN    0    NaN        5.0   \n",
      "95          3  21.0    50.0             1.0  9.0    1  1.375        5.0   \n",
      "\n",
      "    Residence  Result  \n",
      "0         1.0       0  \n",
      "1         1.0       0  \n",
      "2         1.0       0  \n",
      "3         1.0       0  \n",
      "4         1.0       0  \n",
      "..        ...     ...  \n",
      "91        1.0       1  \n",
      "92        1.0       1  \n",
      "93        1.0       1  \n",
      "94        1.0       1  \n",
      "95        1.0       1  \n",
      "\n",
      "[96 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.drop(df.columns[0],axis=1,inplace=True)\n",
    "#df1=pd.read_csv('LBW_Dataset.csv')\n",
    "#print(df,df1)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iter 500:0.3682967297430315\n",
      "Cost after iter 1000:0.36829532594265674\n",
      "Cost after iter 1500:0.3682924836776927\n",
      "Cost after iter 2000:0.3682849940250053\n",
      "Cost after iter 2500:0.36825227333516786\n",
      "Cost after iter 3000:0.36736595467716243\n",
      "Cost after iter 3500:0.3372571816816364\n",
      "Cost after iter 4000:0.32268163206362277\n",
      "Cost after iter 4500:0.31978568405981306\n",
      "Cost after iter 5000:0.31759169696869893\n",
      "Cost after iter 5500:0.3217864538691719\n",
      "Cost after iter 6000:0.32042184597619866\n",
      "Cost after iter 6500:0.31941695620872584\n",
      "Cost after iter 7000:0.3186281515703011\n",
      "Cost after iter 7500:0.31798695029509116\n",
      "Cost after iter 8000:0.31744857556621164\n",
      "Cost after iter 8500:0.31697761389798135\n",
      "Cost after iter 9000:0.3165560255373335\n",
      "Cost after iter 9500:0.316178784644249\n",
      "Cost after iter 10000:0.3158181970592203\n",
      "Cost after iter 10500:0.3245734132202397\n",
      "Cost after iter 11000:0.313212812030097\n",
      "Cost after iter 11500:0.3102566106211421\n",
      "Cost after iter 12000:0.3195406085813871\n",
      "Cost after iter 12500:0.29726794012276064\n",
      "Cost after iter 13000:0.3140992937992616\n",
      "Cost after iter 13500:0.29842222757707343\n",
      "Cost after iter 14000:0.3122497977921911\n",
      "Cost after iter 14500:0.2948151389344625\n",
      "Cost after iter 15000:0.2956088406647589\n",
      "Cost after iter 15500:0.2823295128529488\n",
      "Cost after iter 16000:0.27171647484246964\n",
      "Cost after iter 16500:0.2905904331720287\n",
      "Cost after iter 17000:0.3099524408500947\n",
      "Cost after iter 17500:0.2705052161927686\n",
      "Cost after iter 18000:0.25147556279262184\n",
      "Cost after iter 18500:0.2552406647633998\n",
      "Cost after iter 19000:0.3117232960237134\n",
      "Cost after iter 19500:0.2520996516349444\n",
      "Cost after iter 20000:0.24190885200782408\n",
      "[0.99060119 0.981507   0.83955277 0.99071949 0.89838888 0.89820279\n",
      " 0.93608117 0.67238111 0.77796465 0.90782945 0.86761087 0.65060344\n",
      " 0.93866945 0.25201629 0.24665874 0.55709142 0.81584326 0.87904826\n",
      " 0.99461239 0.38173034 0.99901182 0.97396984 0.79653285 0.89252598\n",
      " 0.78189524 0.85839433 0.24390876 0.92755283 0.85782003]\n"
     ]
    }
   ],
   "source": [
    "nn = NN()\n",
    "nn.fit(X_train,y_train)\n",
    "y_hat = nn.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[4, 1], [4, 20]]\n",
      "\n",
      "\n",
      "Precision : 0.9523809523809523\n",
      "Recall : 0.8333333333333334\n",
      "F1 SCORE : 0.888888888888889\n",
      "Accuracy : 0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "nn.CM(y_test.tolist(),y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
